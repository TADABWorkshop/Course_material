---
title: "Putting all together - beans"
author: "Manuel Tiburtini"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
start <- Sys.time()
library(tidymodels)
library(ggthemes)
library(ggforce)
library(embed)
library(corrplot)
library(learntidymodels)
library(baguette)
library(discrim)
library(uwot)
library(doMC)
library(patchwork)
library(beans)
```

# Beyond the Basics {.unnumbered}

Note: this code largely derive from Tidymodels chapter 16 .

## What Problems Can Dimensionality Reduction Solve?

Dimensionality reduction can be used either in feature engineering or in exploratory data analysis. For example, in high-dimensional biology experiments, one of the first tasks, before any modeling, is to determine if there are any unwanted trends in the data (e.g., effects not related to the question of interest, such as lab-to-lab differences). Debugging the data is difficult when there are hundreds of thousands of dimensions, and dimensionality reduction can be an aid for exploratory data analysis.

::: rmdnote
When starting a new modeling project, reducing the dimensions of the data may provide some intuition about how hard the modeling problem may be.
:::

## A Picture Is Worth a Thousand... Beans {#beans}

Let's walk through how to use dimensionality reduction with `r pkg(recipes)` for an example data set. @beans published a data set of visual characteristics of dried beans and described methods for determining the varieties of dried beans in an image. While the dimensionality of these data is not very large compared to many real-world modeling problems, it does provide a nice working example to demonstrate how to reduce the number of features. From their manuscript:

> The primary objective of this study is to provide a method for obtaining uniform seed varieties from crop production, which is in the form of population, so the seeds are not certified as a sole variety. Thus, a computer vision system was developed to distinguish seven different registered varieties of dry beans with similar features in order to obtain uniform seed classification. For the classification model, images of 13,611 grains of 7 different registered dry beans were taken with a high-resolution camera.

Each image contains multiple beans. The process of determining which pixels correspond to a particular bean is called *image segmentation*. These pixels can be analyzed to produce features for each bean, such as color and morphology (i.e., shape). These features are then used to model the outcome (bean variety) because different bean varieties look different. The training data come from a set of manually labeled images, and this data set is used to create a predictive model that can distinguish between seven bean varieties: Cali, Horoz, Dermason, Seker, Bombay, Barbunya, and Sira. Producing an effective model can help manufacturers quantify the homogeneity of a batch of beans.

There are numerous methods for quantifying shapes of objects [@Mingqiang08]. Many are related to the boundaries or regions of the object of interest. Example of features include:

-   The *area* (or size) can be estimated using the number of pixels in the object or the size of the convex hull around the object.

-   We can measure the *perimeter* using the number of pixels in the boundary as well as the area of the bounding box (the smallest rectangle enclosing an object).

-   The *major axis* quantifies the longest line connecting the most extreme parts of the object. The *minor axis* is perpendicular to the major axis.

-   We can measure the *compactness* of an object using the ratio of the object's area to the area of a circle with the same perimeter. For example, the symbols "`r cli::symbol$bullet`" and "`r cli::symbol$times`" have very different compactness.

-   There are also different measures of how *elongated* or oblong an object is. For example, the *eccentricity* statistic is the ratio of the major and minor axes. There are also related estimates for roundness and convexity.

Shapes such as circles and squares have low eccentricity while oblong shapes have high values. Also, the metric is unaffected by the rotation of the object.

Many of these image features have high correlations; objects with large areas are more likely to have large perimeters. There are often multiple methods to quantify the same underlying characteristics (e.g., size).

In the bean data, `r ncol(beans) - 1` morphology features were computed: `r knitr::combine_words(gsub("_", " ", names(beans)[-ncol(beans)]))`. The latter four are described in @symons1988211.

We can begin by loading the data:

```{r import data}
library(tidymodels)
tidymodels_prefer()
tidyverse_conflicts()
library(beans)

beans
```

```{r looking for the structure data}
library(visdat)

vis_dat(beans)
```

```{r looking for the missingness }
library(visdat)

vis_miss(beans)
#ok!
```

```{r dimensionality-split}
set.seed(1601)
bean_split <- initial_validation_split(beans, strata = class, prop = c(0.75, 0.125))
bean_split

# Return data frames:
bean_train <- training(bean_split)
bean_validation <- validation(bean_split)
bean_test <- testing(bean_split)

set.seed(1602)
# Return an 'rset' object to use with the tune functions:
bean_val <- validation_set(bean_split)
```

```{r visualizing paired data}
library(GGally)
library(ggthemes)
ggpairs(bean_train, columns = 1:10, aes(col=bean_train$class, alpha=0.5),
    lower=list(combo=wrap("facethist", binwidth=10)), progress = FALSE)+
  scale_color_brewer(palette = "Dark2")+
  theme_clean()+
  theme(panel.grid.major.y = element_blank())
```

```{r dimensionality-corr-plot, eval = FALSE}
library(corrplot)
tmwr_cols <- colorRampPalette(c("#91CBD765", "#CA225E"))
bean_train %>% 
  select(-class) %>% 
  cor() %>% 
  corrplot(col = tmwr_cols(200), tl.col = "black", method = "ellipse")
```

```{r visulizing data}
library(GGally)

ggpairs(bean_train, columns = 1:17, aes(col=class, alpha=0.4),
        lower=list(combo=wrap("facethist", binwidth=10)), progress = FALSE)+
  scale_color_brewer(palette = "Dark2")+
  theme_clean()+
  theme(panel.grid.major.y = element_blank())


```

Many of these predictors are highly correlated, such as area and perimeter or shape factors 2 and 3. While we don't take the time to do it here, it is also important to see if this correlation structure significantly changes across the outcome categories. This can help create better models.

```{r dimensionality-initial-rec}
library(bestNormalize)
bean_rec <-
  # Use the training data from the bean_val split object
  recipe(class ~ ., data = bean_train) %>%
  step_zv(all_numeric_predictors()) %>%
  step_orderNorm(all_numeric_predictors()) %>% #transform data using the ORQ (orderNorm) transformation, which approximates the "true" normalizing transformation if one exists.
  step_normalize(all_numeric_predictors())
```

### Data Transformation

```{r let's see the effects of  data trasformation'}
library(patchwork)
p1 <- 
  bean_validation %>% 
  ggplot(aes(x = area)) + 
  geom_histogram(bins = 30, color = "white", fill = "blue", alpha = 1/3) + 
  ggtitle("Original validation set data")+
  theme_clean()+
  theme(panel.grid.major.y = element_blank())

p2 <- 
  bean_rec %>% 
  prep() %>%  # be aware of retain, in big data analyses must be FALSE
  bake(new_data = bean_validation) %>% 
  ggplot(aes(x = area)) + 
  geom_histogram(bins = 30, color = "white", fill = "red", alpha = 1/3) + 
  ggtitle("Processed validation set data")+
  theme_clean()+
  theme(panel.grid.major.y = element_blank())

p1 + p2

#on the paired preprocessed data
bean_rec %>% 
  prep() %>% 
  juice() %>% 
  ggpairs(columns = 1:17, aes(col=class, alpha=0.4),
        lower=list(combo=wrap("facethist", binwidth=10)), progress = FALSE)+
  scale_color_brewer(palette = "Dark2")+
  theme_clean()+
  theme(panel.grid.major.y = element_blank())
```

```{r function to plot dimensionality reduction results}
library(ggforce)
plot_validation_results <- function(recipe, dat = bean_validation) {
  recipe %>%
    # Estimate any additional steps
    prep() %>%
    # Process the data (the validation set by default)
    bake(new_data = dat) %>%
    # Create the scatterplot matrix
    ggplot(aes(x = .panel_x, y = .panel_y, color = class, fill = class)) +
    geom_point(alpha = 0.4, size = 0.5) +
    geom_autodensity(alpha = .3) +
    facet_matrix(vars(-class), layer.diag = 2) + 
    scale_color_brewer(palette = "Dark2") + 
    scale_fill_brewer(palette = "Dark2")
}
```

```{r dimensionality-pca, eval = FALSE}
library(ggthemes)

bean_rec_trained <- prep(bean_rec) 

#lookup to the paired PCA
bean_rec_trained %>%
  step_pca(all_numeric_predictors(), num_comp = 4) %>%
  plot_validation_results() + 
  ggtitle("Principal Component Analysis")+
  theme_clean()+
  theme(panel.grid.major.y = element_blank())


#how does loading contribute to the ordination?
bean_rec_trained %>%
  step_pca(all_numeric_predictors(), num_comp = 4) %>%
  prep() %>% 
  tidy(4) %>% #which step do you want to tidy up?
  filter(component %in% paste0("PC", 1:4)) %>%
  mutate(component = fct_inorder(component)) %>%
  ggplot(aes(value, terms, fill = terms)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~component, nrow = 1) +
  labs(y = NULL)+
  theme_clean()+
  theme(panel.grid.major.y = element_blank())
  
#variance explained function
extract_explained_variace <- function(pca_recipe, n_comp = NULL) {
  if (!tune::is_recipe(pca_recipe)) {
    stop("Input must be a recipe.")
  } else {
    pca_result <- pca_recipe %>%
      prep() %>%
      pluck("steps", 4, "res", "sdev") %>%  #need to be adjusted
      tibble(sdev = .) %>% 
      mutate(var_expl = round((sdev^2 / sum(sdev^2)) * 100, 3), .keep = "unused") %>%
      rownames_to_column("PC") %>%
      mutate(PC = paste0("PC", row_number()),
             PC = factor(PC, levels = unique(PC)))

    if (!is.null(n_comp)) {
      pca_result <- pca_result %>% 
        slice(1:n_comp)
    }

    return(pca_result)
  }
}

explained_var<- bean_rec_trained %>%
  step_pca(all_numeric_predictors(), num_comp = 4) %>%
  extract_explained_variace(.)

#plot the scree plot
bean_rec_trained %>%
  step_pca(all_numeric_predictors(), num_comp = 4) %>%
  extract_explained_variace(.) %>% 
   ggplot(aes(PC, var_expl)) +
  geom_col(fill = "#56B4E9", alpha = 0.8) +
  theme_clean()+
  theme(panel.grid.major.y = element_blank())

#plot top loadings
bean_rec_trained %>%
  step_pca(all_numeric_predictors(), num_comp = 4) %>%
  prep() %>% 
  plot_top_loadings(component_number <= 4, n = 5) +
    scale_fill_brewer(palette = "Paired") +
    ggtitle("Principal Component Analysis")+
  theme_clean()+
  theme(panel.grid.major.y = element_blank())

#plotting pca with explained variance
bean_rec_trained %>%
  step_pca(all_numeric_predictors(), num_comp = 4) %>%
  prep() %>% 
  juice() %>% 
  ggplot(aes(x = PC1, y = PC2, color = class)) +
  xlab(paste0("PC1: ", 
              explained_var$var_expl[1], 
              "%")) +
  ylab(paste0("PC2: ",  
              explained_var$var_expl[2], 
              "%")) +
  geom_point(size = 2, alpha = 0.5) +
  theme_clean()+
  scale_color_brewer(palette = "Dark2") + 
  theme(panel.grid.major.y = element_blank())+
  guides(color =guide_legend(title = "Beans types"))
```

### Partial least squares

PLS is a supervised version of PCA. It tries to find components that simultaneously maximize the variation in the predictors while also maximizing the relationship between those components and the outcome.

```{r partial least squares}

bean_rec_trained %>%
  step_pls(all_numeric_predictors(), outcome = "class", num_comp = 4) %>%
  plot_validation_results() + 
  ggtitle("Partial Least Squares")+
  theme_clean()+
  theme(panel.grid.major.y = element_blank())

```

The first two PLS components plotted in Figure are nearly identical to the first two PCA components! We find this result because those PCA components are so effective at separating the varieties of beans.

```{r dimensionality-pls-loadings, eval = FALSE}
bean_rec_trained %>%
  step_pls(all_numeric_predictors(), outcome = "class", num_comp = 4) %>%
  prep() %>% 
  plot_top_loadings(component_number <= 4, n = 5, type = "pls") + 
  scale_fill_brewer(palette = "Paired") +
  ggtitle("Partial Least Squares")+
  theme_clean()+theme(panel.grid.major.y = element_blank())

```

### Unsupervised and supervised UMAP (**Uniform Manifold Approximation and Projection for Dimension Reduction)**

play with it \| <https://pair-code.github.io/understanding-umap/>

Uniform Manifold Approximation and Projection (UMAP) is a dimension reduction technique that can be used for visualisation similarly to t-SNE, but also for general non-linear dimension reduction. The algorithm is founded on three assumptions about the data

1.  The data is uniformly distributed on Riemannian manifold;

2.  The Riemannian metric is locally constant (or can be approximated as such);

3.  The manifold is locally connected.

It create a graph of neighbors and try to find a similar graph in lower dimensions.

```{r dimensionality-umap, eval = FALSE}
library(embed)
bean_rec_trained %>%
  step_umap(all_numeric_predictors(), num_comp = 4, outcome = "class") %>%
  plot_validation_results() +
  ggtitle("UMAP")
```

```{r dimensionality-umap-supervised 3D, eval=FALSE}
library(plotly)
library(RColorBrewer)

bean_rec_trained %>%
  step_umap(all_numeric_predictors(), outcome = "class", num_comp = 3) %>% 
  prep() %>%
  juice() %>% 
  plot_ly( x = ~UMAP1, y = ~UMAP2, z = ~UMAP3, color = ~bean_train$class, colors = brewer.pal(7, "Dark2")) %>% 
  add_markers()  %>% 
  layout(scene = list(xaxis = list(title = 'UMAP1'), 
                                     yaxis = list(title = 'UMAP2'), 
                                     zaxis = list(title = 'UMAP3'))) 

```

## Modeling {#bean-models}

We are going to explore different models and different recipes both with no dimentionality reduction, with PCA, PSL and UMAP. Let's start the race!

Let's start the race!

#### Specifications

![](Desktop/Material%20TADAB%20Workshop/cover.png)

```{r setting up the engines!}
require(parsnip)
#TIP: use parnsip addins to add models 
library(baguette) #bagging 
library(discrim) #flexible and other discrminant analyses

mlp_spec <-
  mlp(hidden_units = tune(), penalty = tune(), epochs = tune()) %>%
  set_engine('nnet') %>%
  set_mode('classification')


xgb_spec <-
  boost_tree(tree_depth = tune(), trees = tune(), learn_rate = tune(), min_n = tune(), loss_reduction = tune(), sample_size = tune(), stop_iter = tune()) %>%
  set_engine('xgboost') %>%
  set_mode('classification') 

fda_spec <-
  discrim_flexible(
    prod_degree = tune()
  ) %>%
  set_engine('earth')

rda_spec <-
  discrim_regularized(frac_common_cov = tune(), frac_identity = tune()) %>%
  set_engine('klaR')

lda_spec <-
  discrim_linear() %>%
  set_engine('MASS')


rf_spec <-
  rand_forest(mtry = tune(), min_n = tune()) %>%
  set_engine('randomForest') %>%
  set_mode('classification')


svm_lin_spec <-
  svm_linear(cost = tune(), margin = tune()) %>%
  set_engine('kernlab') %>%
  set_mode('classification')


knn_spec <-
  nearest_neighbor(neighbors = tune()) %>%
  set_engine('kknn') %>%
  set_mode('classification')



```

Remember to look at the required preprocessing <https://www.tmwr.org/pre-proc-table.html>

#### Recipes

```{r preparing the receipes - dimensionality-recipes}}
library(bestNormalize)
bean_rec <-
  recipe(class ~ ., data = bean_train) %>%
  step_zv(all_numeric_predictors()) %>%
  step_orderNorm(all_numeric_predictors()) %>%
  step_normalize(all_numeric_predictors())


pls_rec <- 
  bean_rec %>% 
  step_pls(all_numeric_predictors(), 
           outcome = "class",
           num_comp = 5)

umap_rec <-
  bean_rec %>%
  step_umap(
    all_numeric_predictors(),
    outcome = "class"
  )

# 7 models, 16 hyperparameters need to be tuned + 4 from DR
```

#### Workflow sets

```{r workflow sets}

#we need a lot of power... 
parallel::detectCores() # how many cores has your machine? 
doParallel::registerDoParallel(cores = 12)


ctrl <- control_grid(parallel_over = "everything",
                     save_pred = TRUE, allow_par = TRUE)

  

bean_res <- 
  workflow_set(
    preproc = list(basic = bean_rec, 
                   pls = pls_rec, 
                   umap = umap_rec), 
    models = list(fda = fda_spec,
                  rda = rda_spec,
                  rf = rf_spec,
                  mlp = mlp_spec, 
                  xgb= xgb_spec,
                  lda = lda_spec, 
                  svm = svm_lin_spec, 
                  knn= knn_spec)
  ) %>% 
  workflow_map(
    verbose = TRUE,
    seed = 1603,
    resamples = bean_val,
    grid = 10,
    metrics = metric_set(roc_auc),
    control = ctrl
  )

```

#### How win?

```{r who win?}

rankings <- 
  rank_results(bean_res, select_best = TRUE) %>% 
  mutate(method = map_chr(wflow_id, ~ str_split(.x, "_", simplify = TRUE)[1])) 
 
filter(rankings, rank <= 5) %>% dplyr::select(rank, mean, model, method)
```

#### Results

```{r visualizing the results}
bean_res %>% 
  autoplot()+
  theme_clean()+
    theme(panel.grid.major.y = element_blank())

rankings %>% 
  ggplot(aes(x = rank, y = mean, pch = method, color = model)) + 
  geom_point(cex = 3.5) + 
  theme(legend.position = "right") +
  labs(y = "ROC AUC")  +
  geom_text(aes(y = mean - 0.01, label = wflow_id), angle = 90, hjust = 1) +
  lims(y = c(0.9, NA))+
  theme_clean()+
    theme(panel.grid.major.y = element_blank())
```

It is clear from these results that most models give very good performance; there are few bad choices here. For demonstration, we'll use the MLP model as the final model. We will finalize the workflow with the numerically best hyperparameters, fit it to the training set, then evaluate with the test set:

```{r last fit to the test set}

mlp_res <- 
  bean_res %>% 
  extract_workflow("basic_mlp") %>% 
  finalize_workflow(
    bean_res %>% 
      extract_workflow_set_result("basic_mlp") %>% 
      select_best(metric = "roc_auc")
  ) %>% 
  last_fit(split = bean_split, metrics = metric_set(roc_auc))

mlp_wflow_fit <- extract_workflow(mlp_res)

collect_metrics(mlp_res) 
```

Amazing! an Artificial Neural Network Multilayer Perceptron seems to be doing a great jobs with in classifying beans !

### MLOps 

ML operation regards all the aspect when a model is trained and can pass to the next phase, production. R have a nice package to do so, Vetiver.

We can create a vetiver_model() in R from the trained model; a Vetiver model object collects the information needed to store, version, and deploy a trained model.

When deployed, vetiver helps you to deploy, distribute and monitor models during their lifetime for MLOps.

```{r exporting the model for production using vetiver}
devtools::install_github("tidymodels/vetiver-r")
library(butcher) #to reduce the size of models
library(vetiver)
library(plumber)

vetiver_model(mlp_wflow_fit, "bean_mlp")

#you can find by yourself more resouces online


#locally you can export your traine model and data
save(mlp_wflow_fit, bean_train, file = "/Users/manueltiburtini/Desktop/Material\ TADAB\ Workshop\bean_mlp.RData", version = 2, compress = "xz")

library(beepr)
beep()
Sys.time() - start 
##END 23.63608 mins to run
```
